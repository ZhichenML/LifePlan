{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7b63ad32d19a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os, sys\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(48)\n",
    "tf.random.set_random_seed(48)\n",
    "random.seed(48)\n",
    "\n",
    "np.set_printoptions(precision=2, threshold=np.inf)\n",
    "\n",
    "\n",
    "class Maze(object):\n",
    "    WALL = 2\n",
    "    EMPTY = 8\n",
    "    LEFT = 0\n",
    "    RIGHT = 1 # right or forward\n",
    "    def __init__(self, width, length): \n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.maze = np.ones((self.width, self.length)) * Maze.WALL\n",
    "\n",
    "        self.generate_maze()\n",
    "        \n",
    "        #self.maze_mask\n",
    "        #self.shortest_solutions\n",
    "        self.get_shortest_solutions()\n",
    "        \n",
    "        #self.longest_shortest, used to calculate objective value\n",
    "        self.get_longest_shortest_solutions()\n",
    "        \n",
    "        # used to normalize objective value\n",
    "        self.best_score = self.get_attainable_score()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def generate_maze(self):\n",
    "        # generate walls, doors\n",
    "        \n",
    "        spaces = np.random.randint(low=1, high=4, size=self.length)\n",
    "        cum_spaces = np.cumsum(spaces) # leave the first col empty\n",
    " \n",
    "        for ind, val in enumerate(cum_spaces):\n",
    "            if val >= self.length-1:\n",
    "                self.wall_position = cum_spaces[:ind]\n",
    "                break\n",
    "        if self.wall_position[0] > 1:\n",
    "            self.wall_position[0] = 1\n",
    "        if self.wall_position[-1] < self.length-1:\n",
    "            self.wall_position = np.append(self.wall_position, self.length-1)\n",
    "                \n",
    "        self.road_position = np.array([]).astype(np.int)\n",
    "        for ind in np.arange(self.length-1):\n",
    "            if ind not in self.wall_position:\n",
    "                self.road_position = np.append(self.road_position, ind)\n",
    "        \n",
    "        for i in self.road_position:\n",
    "            self.maze[1:-1,i]=Maze.EMPTY\n",
    "        \n",
    "        self.door_position = np.random.randint(low=1, high=self.width-1, size=len(self.wall_position))\n",
    "        #print(self.door_position)\n",
    "    \n",
    "        # get door position\n",
    "        self.door_position = np.zeros(len(self.wall_position), dtype = np.int)\n",
    "        self.door_position[-1] = np.random.randint(low=1, high=self.width-1) #1~self.width-2 available door position\n",
    "        for ind in np.arange(len(self.wall_position)-2, -1, -1):\n",
    "            if self.wall_position[ind] == self.wall_position[ind+1] -1: # two walls together\n",
    "                self.door_position[ind] = self.door_position[ind+1]\n",
    "                \n",
    "            else:\n",
    "                self.door_position[ind] = np.random.randint(low=1, high=self.width-1)\n",
    "        \n",
    "        # Fill door cue\n",
    "        self.maze[ self.door_position[-1], self.wall_position[-1] ] = Maze.RIGHT # default last door due\n",
    "        for i in np.arange(len(self.wall_position)-2, -1, -1):\n",
    "            if self.door_position[i+1] < self.door_position[i]:\n",
    "                self.maze[self.door_position[i], self.wall_position[i]] = Maze.LEFT\n",
    "            else: \n",
    "                self.maze[self.door_position[i], self.wall_position[i]] = Maze.RIGHT\n",
    "                \n",
    "                \n",
    "                \n",
    "       \n",
    "                \n",
    "    def print_maze(self, x=-1, y=-1):\n",
    "        if x>=0 and y>=0:\n",
    "            tmp = self.maze[x,y]\n",
    "            self.maze[x,y] = -1 # position of the agent\n",
    "            \n",
    "        print(\"  \", end=\"\")    \n",
    "        #for i in np.arange(self.length):\n",
    "        #    print('%d ' % i, end='')\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        for j in np.arange(self.width):\n",
    "            print('%d ' % j, end='')\n",
    "            for i in np.arange(self.length):\n",
    "            \n",
    "                if self.maze[j,i]==Maze.WALL: # wall position\n",
    "                    print('H ',end='')\n",
    "                elif self.maze[j,i]==Maze.EMPTY:\n",
    "                    print('  ',end='')# road\n",
    "                elif self.maze[j,i]==-1:\n",
    "                    print('T ',end='')\n",
    "                    self.maze[x,y]= tmp\n",
    "                else:\n",
    "                    print('%d ' % self.maze[j,i], end='')\n",
    "            print('\\n')\n",
    "\n",
    "        \n",
    "    def get_shortest_solutions(self):\n",
    "        # get the shortest length to the end of maze from each layer\n",
    "        \n",
    "        self.maze_mask = np.zeros(self.length, dtype=np.int)\n",
    "        for ind, val in enumerate(self.wall_position):\n",
    "            self.maze_mask[val] = self.door_position[ind]\n",
    "       \n",
    "        self.shortest_solutions = np.zeros(self.length, dtype=np.int)\n",
    "        step = 0\n",
    "        next_wall = self.length-1\n",
    "        for ind in np.arange(self.length-2, -1, -1):\n",
    "            if self.maze_mask[ind] == 0: # road\n",
    "                step += 1\n",
    "                self.shortest_solutions[ind] = step\n",
    "            else: # wall\n",
    "                step += np.abs(self.maze_mask[next_wall] - self.maze_mask[ind])+1 #1 out the door, +diff for vert.\n",
    "                self.shortest_solutions[ind] = step\n",
    "                next_wall = ind\n",
    "        \n",
    "\n",
    "    \n",
    "    def get_distance_escape(self, x, y):\n",
    "        # get the shortest distance to escape from the current position\n",
    "        vertical_distance = 0\n",
    "        if y in self.road_position:\n",
    "            for next_wall_ind in np.arange(y+1, y+4, 1):\n",
    "                if next_wall_ind in self.wall_position: break\n",
    "            vertical_distance = np.abs(self.maze_mask[next_wall_ind] - x)\n",
    "        return self.shortest_solutions[y]+vertical_distance\n",
    "                \n",
    "\n",
    "        \n",
    "    def get_longest_shortest_solutions(self):\n",
    "        # get the shortest length from corner of starting to the end out maze\n",
    "        left = self.get_distance_escape(1,0)\n",
    "        right = self.get_distance_escape(self.width-2,0)\n",
    "        \n",
    "        self.longest_shortest = np.maximum(left, right)+5 # higher than true value\n",
    "    \n",
    "    \n",
    "    def get_attainable_score(self):\n",
    "        #position = []\n",
    "        x = self.door_position[0] # in front of the first door\n",
    "        y = 0\n",
    "        score = np.float32(0)\n",
    "        pass_maze = 0\n",
    "        door_signal=self.maze[self.door_position[0], 1]\n",
    "        for _ in np.arange(LIFE-1, -1, -1):\n",
    "            #position.append([x,y])\n",
    "            if y != self.length-1:\n",
    "                score += (self.longest_shortest - self.get_distance_escape(x,y) )/self.longest_shortest + pass_maze\n",
    "            if self.maze[x, y+1]!=Maze.WALL: # road\n",
    "                y += 1\n",
    "                if y in self.wall_position:\n",
    "                    door_signal = self.maze[x,y]\n",
    "                if y == self.length-1:\n",
    "                    pass_maze += 1\n",
    "                    y=0\n",
    "            else: # wall\n",
    "                if door_signal == 0 and self.maze[x-1,y]==Maze.WALL: # init location make door signal no more signal\n",
    "                    door_signal = 1\n",
    "                if door_signal == 1 and self.maze[x+1,y]==Maze.WALL:\n",
    "                    door_signal = 0\n",
    "                x += int(door_signal*2-1)\n",
    "     \n",
    "        return score\n",
    "\n",
    "\n",
    "    \n",
    "#=========================models===========================================================\n",
    "class NeuroGate(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.func = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(12,)),\n",
    "            tf.keras.layers.Dense(units=128, activation=tf.nn.elu),\n",
    "            tf.keras.layers.Dense(units=128, activation=tf.nn.elu),\n",
    "            tf.keras.layers.Dense(units=12)\n",
    "        ])\n",
    "\n",
    "    def call(self, obs):\n",
    "        return self.func(obs)\n",
    "                   \n",
    "class Agent_circular:\n",
    "    LIFE = 300\n",
    "    def __init__(self, maze, num_gene=10, brain_size=12, genome_len = 5000, probabilistic=True, gene=None):\n",
    "        \n",
    "        self.maze = maze\n",
    "        self.brain_size = brain_size\n",
    "        self.brain = np.zeros(self.brain_size)\n",
    "        self.score = np.float32(0)\n",
    "        self.Gate = NeuroGate()\n",
    "        \n",
    "        self.num_gene = num_gene\n",
    "        self.gene_mask = np.zeros((self.num_gene,2)) # the input output size of each gate\n",
    "        self.max_markov_gate_inputs = 5\n",
    "        self.max_markov_gate_outputs = 5\n",
    "        \n",
    "        \n",
    "        self.markov_gates = []\n",
    "        self.markov_gate_input_ids = []\n",
    "        self.markov_gate_output_ids = []\n",
    "        #self.gene = np.array([Gate(self.gene_mask[i,0], self.gene_mask[i,1]) for i in range(self.num_gene)])\n",
    "        if gene is None:\n",
    "            self.gene = np.random.randint(0, 256, genome_len).astype(np.uint8)\n",
    "            \n",
    "            # Seed the random genome with seed_num_markov_gates Markov Gates\n",
    "            for _ in range(self.num_gene):\n",
    "                start_index = np.random.randint(0, int(len(self.gene) * 0.8))\n",
    "                self.gene[start_index] = 42\n",
    "                self.gene[start_index + 1] = 213\n",
    "            \"\"\"for index_counter in np.arange(self.gene.shape[0] - 1):\n",
    "            # Sequence of 42 then 213 indicates a new Markov Gate\n",
    "                if self.gene[index_counter] == 42 and self.gene[index_counter + 1] == 213:\n",
    "                    self.gene[index_counter] = 85\n",
    "                    self.gene[index_counter+1] = 211\n",
    "                    \n",
    "            \"\"\"\n",
    "        else:\n",
    "            self.gene = np.array(gene, dtype=np.uint8)\n",
    "\n",
    "        self._setup_markov_network(probabilistic)\n",
    "        \n",
    "        \n",
    "        self.end = False # reach the end of maze\n",
    "        self.time_step = 0 # +1 for every move\n",
    "        self.thinking_times = 0 # +1 for every step\n",
    "        #self.life = np.maximum(300, 10*self.maze.length)\n",
    "        self.life = LIFE\n",
    "        self.pass_maze = 0\n",
    "        \n",
    "        #self.position = np.array([self.maze.door_position[0], 0]) # in front of the first door\n",
    "        #self.position = np.array([np.random.choice(np.arange(1,self.maze.width-1)), 0])\n",
    "        self.position = np.array([self.maze.door_position[-1], 0]) # in front of the last door\n",
    "        self.trajectory = np.ones((self.life, 2))*-1\n",
    "        self.trajectory[self.time_step,:] = self.position\n",
    "        \n",
    "        self.door_direction()\n",
    "        self.perception()\n",
    "        \n",
    "    \n",
    "        \n",
    "     # reinit agent after mutation, regenerate markov gates\n",
    "    def reinit(self):\n",
    "        #self.brain[:6] = 0\n",
    "        #self.brain[10:]=0 # keep hidden nodes' state\n",
    "        self.brain = np.zeros(self.brain_size)\n",
    "        self.score = np.float32(0)\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.markov_gates == []:\n",
    "            # Seed the random genome with seed_num_markov_gates Markov Gates\n",
    "            for _ in range(1):\n",
    "                start_index = np.random.randint(0, int(len(self.gene) * 0.8))\n",
    "                self.gene[start_index] = 42\n",
    "                self.gene[start_index + 1] = 213\n",
    "        \"\"\"\n",
    "        self.markov_gates = []\n",
    "        self.markov_gate_input_ids = []\n",
    "        self.markov_gate_output_ids = []\n",
    "\n",
    "        \n",
    "        self._setup_markov_network(probabilistic=True)\n",
    "        \n",
    "        \n",
    "        self.end = False # reach the end of maze\n",
    "        self.time_step = 0 # +1 for every move\n",
    "        self.thinking_times = 0 # +1 for every step\n",
    "        #self.life = np.maximum(300, 10*self.maze.length)\n",
    "        self.life = LIFE\n",
    "        self.pass_maze = 0\n",
    "        \n",
    "        #self.position = np.array([np.random.choice(np.arange(1,self.maze.width-1)), 0])\n",
    "        self.position = np.array([self.maze.door_position[-1], 0]) # in front of the last door\n",
    "        self.trajectory = np.ones((self.life, 2))*-1\n",
    "        self.trajectory[self.time_step,:] = self.position\n",
    "        \n",
    "        self.door_direction()\n",
    "        self.perception()\n",
    "        \n",
    "    # reinit when the genome has no changes, used in fitness evaluation\n",
    "    def simple_reinit(self):\n",
    "        \n",
    "        #self.brain[:6] = 0\n",
    "        #self.brain[10:]=0 # keep hidden nodes' state\n",
    "        self.brain = np.zeros(self.brain_size)\n",
    "        self.score = np.float32(0)\n",
    " \n",
    "        self.end = False # reach the end of maze\n",
    "        self.time_step = 0 # +1 for every move\n",
    "        self.thinking_times = 0 # +1 for every step\n",
    "        #self.life = np.maximum(300, 10*self.maze.length)\n",
    "        self.life = LIFE\n",
    "        self.pass_maze = 0\n",
    "        \n",
    "        #self.position = np.array([np.random.choice(np.arange(1,self.maze.width-1)), 0])\n",
    "        self.position = np.array([self.maze.door_position[-1], 0]) # in front of the last door\n",
    "        self.trajectory = np.ones((self.life, 2))*-1\n",
    "        self.trajectory[self.time_step,:] = self.position\n",
    "        \n",
    "        self.door_direction()\n",
    "        self.perception()\n",
    "    \n",
    "    def _setup_markov_network(self, probabilistic):\n",
    "        \"\"\"Interprets the internal genome into the corresponding Markov Gates\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        probabilistic: bool\n",
    "            Flag indicating whether the Markov Gates are probabilistic or deterministic\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "\n",
    "        \"\"\"\n",
    "        num_gene = 0\n",
    "        tmp = []\n",
    "        for index_counter in np.arange(self.gene.shape[0] - 1):\n",
    "            # Sequence of 42 then 213 indicates a new Markov Gate\n",
    "            if self.gene[index_counter] == 42 and self.gene[index_counter + 1] == 213:\n",
    "                internal_index_counter = (index_counter + 2)%self.gene.shape[0]\n",
    "                num_gene += 1\n",
    "\n",
    "                # Determine the number of inputs and outputs for the Markov Gate\n",
    "                num_inputs = (self.gene[internal_index_counter] % self.max_markov_gate_inputs) + 1\n",
    "                internal_index_counter += 1 \n",
    "                internal_index_counter = internal_index_counter%self.gene.shape[0]\n",
    "                num_outputs = (self.gene[internal_index_counter] % self.max_markov_gate_outputs) + 1\n",
    "                internal_index_counter += 1\n",
    "                internal_index_counter = internal_index_counter%self.gene.shape[0]\n",
    "                \n",
    "                tmp.append([num_inputs, num_outputs]) \n",
    "                # Make sure that the genome is long enough to encode this Markov Gate\n",
    "                if (internal_index_counter +\n",
    "                        (self.max_markov_gate_inputs + self.max_markov_gate_outputs) +\n",
    "                        (2 ** num_inputs) * (2 ** num_outputs)) > self.gene.shape[0]:\n",
    "                    continue\n",
    "\n",
    "                # Determine the states that the Markov Gate will connect its inputs and outputs to\n",
    "                input_state_ids = self.gene[internal_index_counter:internal_index_counter + self.max_markov_gate_inputs][:num_inputs]\n",
    "                input_state_ids = np.mod(input_state_ids, self.brain.shape[0])\n",
    "                input_state_ids = np.sort(input_state_ids)\n",
    "                if len(set(input_state_ids)) < len(input_state_ids):\n",
    "                    input_state_ids = np.sort(random.sample(range(12), num_inputs))\n",
    "                    self.gene[internal_index_counter:internal_index_counter + num_inputs] = input_state_ids\n",
    "                    \n",
    "                #input_state_ids = np.rint(np.array(input_state_ids)*12/255-0.5).astype(np.int32)\n",
    "                internal_index_counter += self.max_markov_gate_inputs\n",
    "                internal_index_counter = internal_index_counter%self.gene.shape[0]\n",
    "\n",
    "                \n",
    "                output_state_ids = self.gene[internal_index_counter:internal_index_counter + self.max_markov_gate_outputs][:num_outputs]\n",
    "                output_state_ids = np.mod(output_state_ids, 6)+6\n",
    "                output_state_ids = np.sort(output_state_ids)\n",
    "                if len(set(output_state_ids)) < len(output_state_ids):\n",
    "                    output_state_ids = np.sort(random.sample(range(6,12), num_outputs))\n",
    "                    self.gene[internal_index_counter:internal_index_counter + num_outputs] = output_state_ids\n",
    "                \n",
    "                #output_state_ids = np.rint(np.array(output_state_ids*6/255+5.5)).astype(np.int32)\n",
    "                internal_index_counter += self.max_markov_gate_outputs\n",
    "                internal_index_counter = internal_index_counter%self.gene.shape[0]\n",
    "\n",
    "                self.markov_gate_input_ids.append(input_state_ids)\n",
    "                self.markov_gate_output_ids.append(output_state_ids)\n",
    "\n",
    "                # Interpret the probability table for the Markov Gate\n",
    "                markov_gate = copy.copy(self.gene[internal_index_counter:internal_index_counter + (2 ** num_inputs) * (2 ** num_outputs)])\n",
    "                markov_gate = markov_gate.reshape((2 ** num_inputs, 2 ** num_outputs))\n",
    "\n",
    "                if probabilistic:  # Probabilistic Markov Gates\n",
    "                    markov_gate = markov_gate.astype(np.float64) / np.sum(markov_gate, axis=1, dtype=np.float64)[:, None]\n",
    "                    # Precompute the cumulative sums for the activation function\n",
    "                    markov_gate = np.cumsum(markov_gate, axis=1, dtype=np.float64)\n",
    "                else:  # Deterministic Markov Gates\n",
    "                    row_max_indices = np.argmax(markov_gate, axis=1)\n",
    "                    markov_gate[:, :] = 0\n",
    "                    markov_gate[np.arange(len(row_max_indices)), row_max_indices] = 1\n",
    "\n",
    "                self.markov_gates.append(markov_gate)\n",
    "        self.num_gene = num_gene\n",
    "        self.gene_mask = np.array(tmp)\n",
    "        \n",
    "       # print(self.all_output_idx)\n",
    "        all_outputs_idx = np.array([], dtype = np.int)\n",
    "        for gate_output in self.markov_gate_output_ids:\n",
    "            all_outputs_idx = np.concatenate((all_outputs_idx, gate_output))\n",
    "        self.all_outputs_idx = np.unique(all_outputs_idx)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    def init_locate(self):\n",
    "        # if the agent reaches the end of maze, pull it back to the origin\n",
    "        \n",
    "        #self.position = np.array([np.random.choice(np.arange(1,self.maze.width-1)), 0])\n",
    "        self.position = np.array([self.maze.door_position[-1], 0]) # in front of the last door\n",
    "        self.end = False\n",
    "    \n",
    "        self.brain[:6] = 0 # reset brain\n",
    "        self.brain[10:]=0 # keep hidden nodes' state\n",
    "        \n",
    "        self.door_direction()\n",
    "        self.perception()\n",
    "    \n",
    "\n",
    "        \n",
    "    def door_direction(self):\n",
    "        # let the agent know the first door's position\n",
    "        \n",
    "        next_wall = self.maze.wall_position[0] # the first wall\n",
    "        left = self.maze.maze[1:self.position[0], next_wall]\n",
    "        right = self.maze.maze[self.position[0]:self.maze.width-1, next_wall]\n",
    "        \n",
    "        for land in left:\n",
    "            if land != Maze.WALL: \n",
    "                self.brain[3] = 0\n",
    "                break\n",
    "        for land in right:\n",
    "            if land != Maze.WALL: \n",
    "                self.brain[3] = 1\n",
    "                break\n",
    "        self.brain[3] = 0 # cancel information\n",
    "                \n",
    "    def perception(self):\n",
    "        x,y = self.position\n",
    "        #print(\"x=%d, y=%d\", (x,y))\n",
    "        # reset agent's input before set new values\n",
    "        #self.brain[0:3] = 0\n",
    "        #self.brain[4:6] =0\n",
    "        self.brain[:6]=0\n",
    "        \n",
    "        if self.maze.maze[x,y+1] == Maze.WALL:\n",
    "            self.brain[0]=1\n",
    "        else: self.brain[0]=0\n",
    "        \n",
    "        if self.maze.maze[x-1,y+1] == Maze.WALL:\n",
    "            self.brain[1]=1\n",
    "        else: self.brain[1]=0\n",
    "        \n",
    "        if self.maze.maze[x+1,y+1] == Maze.WALL:\n",
    "            self.brain[2] = 1\n",
    "        else: self.brain[2]=0\n",
    "        \n",
    "        if self.maze.maze[x-1,y] == Maze.WALL:\n",
    "            self.brain[4]=1\n",
    "        else: self.brain[4]=0\n",
    "        \n",
    "        if self.maze.maze[x+1,y] == Maze.WALL:\n",
    "            self.brain[5]=1\n",
    "        else: self.brain[5]=0\n",
    "        \n",
    "        if y in self.maze.wall_position:\n",
    "            self.brain[3] = self.maze.maze[x, y]\n",
    "        \n",
    "    \n",
    "    def brain_update(self, times=1):\n",
    "        self.perception()\n",
    "        observation = np.copy(self.brain)\n",
    "        \n",
    "        # Save original input values\n",
    "        original_input_values = np.copy(self.brain[:6])\n",
    "        \n",
    "        for _ in range(times):\n",
    "            next_brain = np.copy(self.brain)\n",
    "            next_brain[self.all_outputs_idx] = 0\n",
    "            # NOTE: This routine can be refactored to use NumPy if larger MNs are being used\n",
    "            # See implementation at https://github.com/rhiever/MarkovNetwork/blob/a381aa9919bb6898b56f678e08127ba6e0eef98f/MarkovNetwork/MarkovNetwork.py#L162:L169\n",
    "            for markov_gate, mg_input_ids, mg_output_ids in zip(self.markov_gates, self.markov_gate_input_ids,\n",
    "                                                                self.markov_gate_output_ids):\n",
    "\n",
    "                mg_input_index, marker = 0, 1\n",
    "                # Create an integer from bytes representation (loop is faster than previous implementation)\n",
    "                for mg_input_id in reversed(mg_input_ids):\n",
    "                    if self.brain[mg_input_id]:\n",
    "                        mg_input_index += marker\n",
    "                    marker *= 2\n",
    "\n",
    "                # Determine the corresponding output values for this Markov Gate\n",
    "                roll = np.random.uniform()  # sets a roll value\n",
    "                markov_gate_subarray = markov_gate[mg_input_index,:]  # selects a Markov Gate subarray\n",
    "\n",
    "                # Searches for the first value where markov_gate > roll\n",
    "                for i, markov_gate_element in enumerate(markov_gate_subarray):\n",
    "                    if markov_gate_element >= roll:\n",
    "                        mg_output_index = i\n",
    "                        break\n",
    "                #mg_output_index = np.random.choice(len(markov_gate_subarray),p = markov_gate_subarray)\n",
    "                # Converts the index into a string of '1's and '0's (binary representation)\n",
    "                mg_output_values = bin(mg_output_index)  # bin() is much faster than np.binaryrepr()\n",
    "\n",
    "                # diff_len deals with the lack of the width argument there was on np.binaryrepr()\n",
    "                \"\"\"diff_len = mg_output_ids.shape[0] - (len(mg_output_values) - 2)\n",
    "                print(\"\\n\")\n",
    "                print(mg_output_ids.shape)\n",
    "                print(\"\\n\")\n",
    "                \"\"\"\n",
    "                # Loops through 'mg_output_values' and alter 'self.states'\n",
    "                for i, mg_output_value in enumerate(mg_output_values[2:]):\n",
    "                    if mg_output_value == '1':\n",
    "                        next_brain[mg_output_ids[i]] = 1   #.astype(np.int32)\n",
    "                \n",
    "                    \n",
    "            # Replace original input values\n",
    "            self.brain = np.copy(next_brain)\n",
    "            self.brain[:6] = original_input_values\n",
    "        return observation, self.brain[6:]\n",
    "\n",
    "            \n",
    "    \n",
    "    def step(self):\n",
    "        x,y = self.position\n",
    "        r = (self.maze.longest_shortest - self.maze.get_distance_escape(x,y))/self.maze.longest_shortest + self.pass_maze\n",
    "        self.score +=  r\n",
    "        #print(\"x=%d, y=%d, escape_distance=%d, score=%f \" % (x,y,agent.maze.get_distance_escape(x,y), agent.score))\n",
    "        #print(\"value=%f \", (agent.maze.longest_shortest - agent.maze.get_distance_escape(x,y))/agent.maze.longest_shortest)\n",
    "        \n",
    "        \n",
    "        fitness = 0\n",
    "        time_step_shot = self.time_step\n",
    "        self.thinking_times = self.thinking_times + 1\n",
    "        # print(\"time_step:%d\" % self.time_step)\n",
    "        # print(\"thinking time: %d\" % self.thinking_times)\n",
    "        if self.thinking_times>=self.life-1:# or self.thinking_times >= 3000: \n",
    "            self.end = True\n",
    "            fitness = self.get_fitness()\n",
    "            \n",
    "        elif self.brain[10] == 1 and self.brain[11] == 0:\n",
    "            #if self.maze.maze[x+1,y]==Maze.WALL:\n",
    "            #    self.brain[10] = 0\n",
    "            #    self.brain[11] = 1\n",
    "            #else:\n",
    "            if  self.maze.maze[x+1,y] != Maze.WALL:\n",
    "                self.position = x+1, y\n",
    "                self.time_step = self.time_step+1\n",
    "        elif self.brain[10] == 0 and self.brain[11] == 1:\n",
    "            #if self.maze.maze[x-1,y] == Maze.WALL:\n",
    "            #    self.brain[10] = 1\n",
    "            #    self.brain[11] = 0\n",
    "            #else:\n",
    "            if  self.maze.maze[x-1,y] != Maze.WALL:\n",
    "                self.position = x-1, y\n",
    "                self.time_step = self.time_step+1\n",
    "                \n",
    "        elif self.brain[10] == 1 and self.brain[11] == 1:\n",
    "            if self.maze.maze[x,y+1] != Maze.WALL:\n",
    "                self.position = x,y+1\n",
    "                self.time_step = self.time_step+1\n",
    "            \"\"\"\n",
    "            elif y in self.maze.wall_position: # in a door\n",
    "                self.position = x,y+1\n",
    "                self.time_step = self.time_step+1\n",
    "            elif y+1 in self.maze.wall_position and self.maze.maze[x,y+1]!=2: # before a door\n",
    "                #print('before a door >;<')\n",
    "                self.position = x,y+1\n",
    "                self.time_step = self.time_step+1\n",
    "            \"\"\"\n",
    "            x,y = self.position\n",
    "            if y == self.maze.length-1: # reach the end of the maze\n",
    "                self.pass_maze = self.pass_maze + 1\n",
    "                self.init_locate()\n",
    "            \n",
    "        elif self.brain[10] == 0 and self.brain[11] == 0:\n",
    "            self.position = x,y\n",
    "            self.time_step = self.time_step+1\n",
    "            '''else:\n",
    "                # shouldn't have this\n",
    "                self.brain[10] = 1\n",
    "                self.brain[11] = 0\n",
    "            '''    \n",
    "        '''elif self.brain[10] == 0 and self.brain[11] == 0:\n",
    "            self.brain[10] = 0\n",
    "            self.brain[11] = 1\n",
    "        ''' \n",
    "        \n",
    "        # if the brain's order is legal, keep it\n",
    "        # illegal order is omitted\n",
    "        if self.time_step > time_step_shot:    \n",
    "            self.trajectory[self.time_step,:] = self.position\n",
    "        \n",
    "        return fitness, r\n",
    "    \n",
    "    def get_fitness(self):\n",
    "        \n",
    "        return self.score/self.maze.best_score \n",
    "        \n",
    "        \"\"\" old implementation\n",
    "        x,y = self.position\n",
    "        tmp1 = (y)/self.maze.length\n",
    "        tmp2 = self.pass_maze\n",
    "        return tmp1+tmp2\n",
    "        \"\"\"\n",
    "        \n",
    "    def copy(self, agent):\n",
    "        self.brain_size = agent.brain_size\n",
    "        self.maze = agent.maze\n",
    "        self.brain = agent.brain\n",
    "        \n",
    "        self.markov_gates = agent.markov_gates\n",
    "        self.markov_gate_input_ids = agent.markov_gate_input_ids\n",
    "        self.markov_gate_output_ids = agent.markov_gate_output_ids\n",
    "        \n",
    "        \n",
    "        self.num_gene = agent.num_gene\n",
    "        self.gene_mask = agent.gene_mask # the input output size of each gate\n",
    "        self.gene = agent.gene\n",
    "        \n",
    "        self.end = agent.end # reach the end of maze\n",
    "        self.time_step = agent.time_step\n",
    "        self.thinking_times = agent.thinking_times\n",
    "        self.life = agent.life\n",
    "        self.pass_maze = agent.pass_maze\n",
    "        \n",
    "        self.position = agent.position\n",
    "        self.trajectory = agent.trajectory\n",
    "        \n",
    "        self.perception()\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "def test():        \n",
    "    maze = Maze(7,10)\n",
    "    maze.print_maze()\n",
    " \n",
    "    agent = Agent_circular(maze)\n",
    "    gene = agent.gene\n",
    "    num_gene = agent.num_gene\n",
    "    gene_mask = agent.gene_mask\n",
    "    gates = agent.markov_gates\n",
    "    for ind in np.arange(10):  \n",
    "        while (agent.end == False):\n",
    "            #maze.print_maze(agent.position[0], agent.position[1])\n",
    "            agent.brain_update(1)\n",
    "            #print(agent.brain)\n",
    "            fitness = agent.step()\n",
    "\n",
    "\n",
    "        print(fitness)\n",
    "        #print(agent.trajectory)\n",
    "        agent.reinit()\n",
    "\n",
    "#np.random.seed(9)\n",
    "#test()\n",
    "\n",
    "        \n",
    "                \n",
    "            \n",
    "    \n",
    "        \n",
    "#np.random.seed(9)\n",
    "#import cProfile\n",
    "#cProfile.run('test()')\n",
    "\n",
    "        \n",
    "                \n",
    "            \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================utils===========================================================\n",
    "def calculate_discout_reward(rewards, gamma):\n",
    "    discounted_reward = []\n",
    "    cumulative_sum = 0\n",
    "    for i, r in enumerate(reversed(rewards)):\n",
    "        cumulative_sum = cumulative_sum*gamma + r\n",
    "        discounted_reward.append(cumulative_sum)\n",
    "    return discounted_reward[::-1]\n",
    "\n",
    "def calculate_discout_reward_window(reward, gamma, length=3):\n",
    "    target_discount_reward = []\n",
    "    convolution_filter = [gamma**i for i in range(length)]\n",
    "    return np.convolve(reward, convolution_filter, 'valid')\n",
    "\n",
    "\n",
    "\n",
    "#=========================Agent===========================================================\n",
    "def collect_experience(env, agent, number_action=6):\n",
    "\n",
    "    observations, rewards, action_taken, is_not_done = [], [], [], []\n",
    "    action_probs = []\n",
    "    \n",
    "    agent.perception()\n",
    "    obs = np.copy(agent.brain)\n",
    "    \n",
    "    while (agent.end == False):        \n",
    "                    \n",
    "        out = agent.Gate(\n",
    "            tf.expand_dims(\n",
    "                tf.convert_to_tensor(obs, dtype=tf.float32), axis=0\n",
    "            ))\n",
    "\n",
    "        action_prob = np.zeros((1,12))\n",
    "        for i in range(0,11,2):\n",
    "            action_prob[0, i:i+2] = tf.nn.softmax(out[0,i:i+2])\n",
    "\n",
    "        # Sample\n",
    "        samples = np.zeros(6, dtype =np.int)\n",
    "        for i in range(6):\n",
    "            tmp = np.zeros((1,2))\n",
    "            tmp[0] = action_prob[0, 2*i: 2*i+2]\n",
    "            samples[i] = tf.random.multinomial(tf.log(tmp), 1).numpy()[0][0]\n",
    "            \n",
    "        action = np.zeros((number_action, 2))\n",
    "        for i in range(6):\n",
    "            action[i, samples[i]] = 1\n",
    "        action = action.flatten()\n",
    "\n",
    "        agent.brain[6:] = samples\n",
    "\n",
    "        _,r = agent.step()\n",
    "        agent.perception()\n",
    "        next_obs = np.copy(agent.brain)\n",
    "\n",
    "        observations.append(obs)\n",
    "        rewards.append(r)\n",
    "        action_taken.append(action)\n",
    "\n",
    "\n",
    "        obs = next_obs\n",
    "            \n",
    "    observations.append(obs)\n",
    "\n",
    "    return np.stack(observations), np.stack(rewards), np.stack(action_taken)\n",
    "\n",
    "            \n",
    "            \n",
    "#=========================main===========================================================\n",
    "logger = logging.getLogger(os.path.basename(sys.argv[0]))\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    # -------------------- * --------------------\n",
    "    argparser = argparse.ArgumentParser('PG', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    argparser.add_argument('--gamma', action=\"store\", type=float, default=0.99)\n",
    "    argparser.add_argument('--learning-rate', action=\"store\", type=float, default=8e-4)\n",
    "    argparser.add_argument('--episode-train', action=\"store\", type=int, default=500)\n",
    "\n",
    "    argparser.add_argument('--output-save-img', action=\"store\", type=str, default=None)\n",
    "\n",
    "    args = argparser.parse_args(argv)\n",
    "    gamma = args.gamma\n",
    "    learning_rate = args.learning_rate\n",
    "    episode_train = args.episode_train\n",
    "    output_save_img = args.output_save_img\n",
    "    # -------------------- * --------------------\n",
    "    \"\"\"\n",
    "    \n",
    "    gamma =  0.99 \n",
    "    episode_train = 10\n",
    "    learning_rate = 8e-4 \n",
    "\n",
    "    maze = Maze(10,50)\n",
    "    agent = Agent_circular(maze)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "    average_reward, reward_curve = 0, []\n",
    "\n",
    "    for eps in range(episode_train):\n",
    "        observation_rollout, reward_rollout, action_rollout = collect_experience(agent.maze, agent)\n",
    "        discounted_reward_rollout = calculate_discout_reward(reward_rollout, gamma)\n",
    "\n",
    "        # Remove last observation\n",
    "        observation_rollout = observation_rollout[:-1]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(agent.Gate.variables)\n",
    "\n",
    "            out = agent.Gate(tf.convert_to_tensor(observation_rollout, dtype=tf.float32))\n",
    "\n",
    "            action_prob = np.zeros((1,12))\n",
    "            for i in range(0,11,2):\n",
    "                action_prob[0, i:i+2] = tf.nn.softmax(out[0,i:i+2])\n",
    "            action_prob = tf.log(action_prob)\n",
    "\n",
    "            all_prob_masked = tf.reduce_sum(action_rollout *  action_prob, axis=-1)\n",
    "            loss = tf.reduce_sum(all_prob_masked * discounted_reward_rollout * -1)\n",
    "\n",
    "        grad = tape.gradient(loss, agent.Gate.variables)\n",
    "        optimizer.apply_gradients(zip(grad, agent.Gate.variables))\n",
    "\n",
    "        average_reward += sum(reward_rollout)\n",
    "\n",
    "        if eps%5 == 0 and eps > 0:\n",
    "            average_reward /= 2\n",
    "            print(\"Currently in episode %d and the average reward is %f\" % (eps, average_reward))\n",
    "            #logger.info(\"Currently in episode {eps} and the average reward is {average_reward}\" )\n",
    "            reward_curve.append(average_reward)\n",
    "            average_reward = 0\n",
    "\n",
    "    if output_save_img is not None:\n",
    "        sns.lineplot(y=reward_curve, x=list(range(len(reward_curve))))\n",
    "        plt.savefig(output_save_img)\n",
    "\n",
    "        \n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print(' '.join(sys.argv))\n",
    "\n",
    "main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
