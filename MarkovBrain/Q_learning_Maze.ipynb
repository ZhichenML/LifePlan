{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import os, sys\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "np.random.seed(15)\n",
    "tf.random.set_random_seed(15)\n",
    "random.seed(15)\n",
    "\n",
    "np.set_printoptions(precision=2, threshold=np.inf)\n",
    "\n",
    "class Maze(object):\n",
    "    WALL = 2\n",
    "    EMPTY = 8\n",
    "    LEFT = 0\n",
    "    RIGHT = 1 # right or forward\n",
    "    def __init__(self, width, length): \n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.maze = np.ones((self.width, self.length)) * Maze.WALL\n",
    "\n",
    "        self.generate_maze()\n",
    "        \n",
    "        #self.maze_mask\n",
    "        #self.shortest_solutions\n",
    "        self.get_shortest_solutions()\n",
    "        \n",
    "        #self.longest_shortest, used to calculate objective value\n",
    "        self.get_longest_shortest_solutions()\n",
    "        \n",
    "        # used to normalize objective value\n",
    "        self.best_score = self.get_attainable_score()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def generate_maze(self):\n",
    "        # generate walls, doors\n",
    "        \n",
    "        spaces = np.random.randint(low=1, high=4, size=self.length)\n",
    "        cum_spaces = np.cumsum(spaces) # leave the first col empty\n",
    " \n",
    "        for ind, val in enumerate(cum_spaces):\n",
    "            if val >= self.length-1:\n",
    "                self.wall_position = cum_spaces[:ind]\n",
    "                break\n",
    "        if self.wall_position[0] > 1:\n",
    "            self.wall_position[0] = 1\n",
    "        if self.wall_position[-1] < self.length-1:\n",
    "            self.wall_position = np.append(self.wall_position, self.length-1)\n",
    "                \n",
    "        self.road_position = np.array([]).astype(np.int)\n",
    "        for ind in np.arange(self.length-1):\n",
    "            if ind not in self.wall_position:\n",
    "                self.road_position = np.append(self.road_position, ind)\n",
    "        \n",
    "        for i in self.road_position:\n",
    "            self.maze[1:-1,i]=Maze.EMPTY\n",
    "        \n",
    "        self.door_position = np.random.randint(low=1, high=self.width-1, size=len(self.wall_position))\n",
    "        #print(self.door_position)\n",
    "    \n",
    "        # get door position\n",
    "        self.door_position = np.zeros(len(self.wall_position), dtype = np.int)\n",
    "        self.door_position[-1] = np.random.randint(low=1, high=self.width-1) #1~self.width-2 available door position\n",
    "        for ind in np.arange(len(self.wall_position)-2, -1, -1):\n",
    "            if self.wall_position[ind] == self.wall_position[ind+1] -1: # two walls together\n",
    "                self.door_position[ind] = self.door_position[ind+1]\n",
    "                \n",
    "            else:\n",
    "                self.door_position[ind] = np.random.randint(low=1, high=self.width-1)\n",
    "        \n",
    "        # Fill door cue\n",
    "        self.maze[ self.door_position[-1], self.wall_position[-1] ] = Maze.RIGHT # default last door due\n",
    "        for i in np.arange(len(self.wall_position)-2, -1, -1):\n",
    "            if self.door_position[i+1] < self.door_position[i]:\n",
    "                self.maze[self.door_position[i], self.wall_position[i]] = Maze.LEFT\n",
    "            else: \n",
    "                self.maze[self.door_position[i], self.wall_position[i]] = Maze.RIGHT\n",
    "                \n",
    "                \n",
    "                \n",
    "       \n",
    "                \n",
    "    def print_maze(self, x=-1, y=-1):\n",
    "        if x>=0 and y>=0:\n",
    "            tmp = self.maze[x,y]\n",
    "            self.maze[x,y] = -1 # position of the agent\n",
    "            \n",
    "        print(\"  \", end=\"\")    \n",
    "        #for i in np.arange(self.length):\n",
    "        #    print('%d ' % i, end='')\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        for j in np.arange(self.width):\n",
    "            print('%d ' % j, end='')\n",
    "            for i in np.arange(self.length):\n",
    "            \n",
    "                if self.maze[j,i]==Maze.WALL: # wall position\n",
    "                    print('H ',end='')\n",
    "                elif self.maze[j,i]==Maze.EMPTY:\n",
    "                    print('  ',end='')# road\n",
    "                elif self.maze[j,i]==-1:\n",
    "                    print('T ',end='')\n",
    "                    self.maze[x,y]= tmp\n",
    "                else:\n",
    "                    print('%d ' % self.maze[j,i], end='')\n",
    "            print('\\n')\n",
    "\n",
    "        \n",
    "    def get_shortest_solutions(self):\n",
    "        # get the shortest length to the end of maze from each layer\n",
    "        \n",
    "        self.maze_mask = np.zeros(self.length, dtype=np.int)\n",
    "        for ind, val in enumerate(self.wall_position):\n",
    "            self.maze_mask[val] = self.door_position[ind]\n",
    "       \n",
    "        self.shortest_solutions = np.zeros(self.length, dtype=np.int)\n",
    "        step = 0\n",
    "        next_wall = self.length-1\n",
    "        for ind in np.arange(self.length-2, -1, -1):\n",
    "            if self.maze_mask[ind] == 0: # road\n",
    "                step += 1\n",
    "                self.shortest_solutions[ind] = step\n",
    "            else: # wall\n",
    "                step += np.abs(self.maze_mask[next_wall] - self.maze_mask[ind])+1 #1 out the door, +diff for vert.\n",
    "                self.shortest_solutions[ind] = step\n",
    "                next_wall = ind\n",
    "        \n",
    "\n",
    "    \n",
    "    def get_distance_escape(self, x, y):\n",
    "        # get the shortest distance to escape from the current position\n",
    "        vertical_distance = 0\n",
    "        if y in self.road_position:\n",
    "            for next_wall_ind in np.arange(y+1, y+4, 1):\n",
    "                if next_wall_ind in self.wall_position: break\n",
    "            vertical_distance = np.abs(self.maze_mask[next_wall_ind] - x)\n",
    "        return self.shortest_solutions[y]+vertical_distance\n",
    "                \n",
    "\n",
    "        \n",
    "    def get_longest_shortest_solutions(self):\n",
    "        # get the shortest length from corner of starting to the end out maze\n",
    "        left = self.get_distance_escape(1,0)\n",
    "        right = self.get_distance_escape(self.width-2,0)\n",
    "        \n",
    "        self.longest_shortest = np.maximum(left, right)+5 # higher than true value\n",
    "    \n",
    "    \n",
    "    def get_attainable_score(self):\n",
    "        position = []\n",
    "        x = self.door_position[0] # in front of the first door\n",
    "        y = 0\n",
    "        score = np.float32(0)\n",
    "        pass_maze = 0\n",
    "        door_signal=self.maze[self.door_position[0], 1]\n",
    "        r=[]\n",
    "        for _ in np.arange(Agent.LIFE, -1, -1):\n",
    "            position.append([x,y])\n",
    "            if y != self.length-1:\n",
    "                r.append((self.longest_shortest - self.get_distance_escape(x,y) )/self.longest_shortest + pass_maze)\n",
    "                score += (self.longest_shortest - self.get_distance_escape(x,y) )/self.longest_shortest + pass_maze\n",
    "            if self.maze[x, y+1]!=Maze.WALL: # road\n",
    "                y += 1\n",
    "                if y in self.wall_position:\n",
    "                    door_signal = self.maze[x,y]\n",
    "                if y == self.length-1:\n",
    "                    pass_maze += 1\n",
    "                    y=0\n",
    "            else: # wall\n",
    "                if door_signal == 0 and self.maze[x-1,y]==Maze.WALL: # init location make door signal no more signal\n",
    "                    door_signal = 1\n",
    "                if door_signal == 1 and self.maze[x+1,y]==Maze.WALL:\n",
    "                    door_signal = 0\n",
    "                x += int(door_signal*2-1)\n",
    "        \n",
    "        #print(position)\n",
    "        self.average_reward = np.mean(r)\n",
    "     \n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    LIFE = 300\n",
    "    num_inputs = 6\n",
    "    num_memory = 1\n",
    "    num_outputs = 2\n",
    "    brain_size = num_inputs + num_memory + num_outputs\n",
    "    \n",
    "    def __init__(self, maze):\n",
    "        \n",
    "        self.maze = maze\n",
    "        self.brain_size = Agent.brain_size\n",
    "        self.brain = np.zeros(self.brain_size)\n",
    "        self.score = np.float32(0)\n",
    "        \n",
    "        self.input_ids=[]\n",
    "        self.output_ids=[]\n",
    "        self.gates = []\n",
    "        \n",
    "        self.best_input_ids=[[0,3,4,5,6]]\n",
    "        self.best_output_ids=[[6,7,8]]\n",
    "        self.best_gates =[]        \n",
    "        self.best_gates.append(np.array([[0,0,0,0,0,0,1,0],\n",
    "                            [0,0,0,0,1,0,0,0],\n",
    "                            [0,0,0,0,0,0,1,0],\n",
    "                            [0,0,0,0,1,0,0,0],\n",
    "                            [0,0,0,0,0,0,1,0],\n",
    "                            [0,0,0,1,0,0,0,0],\n",
    "                            [0,0,0,0,0,0,1,0],\n",
    "                            [0,0,0,1,0,0,0,0],\n",
    "                            [0,0,0,0,0,0,1,0],\n",
    "                            [0,0,0,0,1,0,0,0],\n",
    "                            [0,0,0,0,0,0,1,0],\n",
    "                            [0,0,0,0,1,0,0,0],\n",
    "                            [0,0,0,0,0,0,1,0],\n",
    "                            [1,0,0,0,0,0,0,0],\n",
    "                            [0,0,0,0,0,0,0,1],\n",
    "                            [1,0,0,0,0,0,0,0],\n",
    "                            [0,0,0,0,0,0,0,1],\n",
    "                            [0,0,0,1,0,0,0,0],\n",
    "                            [0,0,0,0,0,0,0,1],\n",
    "                            [0,0,0,1,0,0,0,0],\n",
    "                            [0,0,0,0,0,0,0,1],\n",
    "                            [0,0,0,1,0,0,0,0],\n",
    "                            [0,0,0,0,0,0,0,1],\n",
    "                            [0,0,0,1,0,0,0,0],\n",
    "                            [0,0,0,0,0,0,0,1],\n",
    "                            [0,0,0,0,1,0,0,0],\n",
    "                            [0,0,0,0,0,0,0,1],\n",
    "                            [0,0,0,0,1,0,0,0],\n",
    "                            [0,0,0,0,0,0,1,0],\n",
    "                            [1,0,0,0,0,0,0,0],\n",
    "                            [0,0,0,0,0,0,0,1],\n",
    "                            [1,0,0,0,0,0,0,0]]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.end = False # reach the end of maze\n",
    "        self.time_step = 0 # +1 for every move\n",
    "        self.thinking_times = 0 # +1 for every step\n",
    "        self.life = Agent.LIFE\n",
    "        self.pass_maze = 0\n",
    "        \n",
    "        #self.position = np.array([self.maze.door_position[0], 0]) # in front of the first door\n",
    "        #self.position = np.array([np.random.choice(np.arange(1,self.maze.width-1)), 0])\n",
    "        self.position = np.array([self.maze.door_position[-1], 0]) # in front of the last door\n",
    "        self.trajectory = np.ones((self.life, 2))*-1\n",
    "        self.trajectory[self.time_step,:] = self.position\n",
    "        \n",
    "        self.door_direction()\n",
    "        self.perception()\n",
    "  \n",
    "        \n",
    "    def human_brain_update(self):\n",
    "        x,y = self.position\n",
    "        if y == self.maze.length-1: # reach the end of the maze\n",
    "            self.pass_maze = self.pass_maze + 1\n",
    "            self.init_locate()\n",
    "       \n",
    "        if self.brain[4]==1 and self.brain[5]==1:\n",
    "            self.brain[6] = self.brain[3] # sure it is a due\n",
    "             \n",
    "            \n",
    "        if self.brain[0] == 0:\n",
    "            self.brain[7], self.brain[8] = 1,1\n",
    "        else:\n",
    "            if self.brain[6] == 0: # turn left\n",
    "                if self.brain[4] == 0: # no wall\n",
    "                    self.brain[7], self.brain[8] = 0,1\n",
    "                else: #wall\n",
    "                    self.brain[7], self.brain[8] = 1,0\n",
    "                    self.brain[6]=1\n",
    "   \n",
    "                \n",
    "            else: # turn right\n",
    "                if self.brain[5] == 0:\n",
    "                    self.brain[7], self.brain[8] = 1,0\n",
    "                else:\n",
    "                    self.brain[7], self.brain[8] = 0,1\n",
    "                    self.brain[6]=0\n",
    "\n",
    "    \n",
    "    def brain_update(self):\n",
    "        # differ with gate\n",
    "        \n",
    "        \n",
    "        next_brain = np.copy(self.brain)\n",
    "        #next_brain[6:] = 0\n",
    "        \n",
    "        all_outputs_idx = np.array([])\n",
    "        for gate_output in self.output_ids:\n",
    "            all_outputs_idx = np.concatenate((all_outputs_idx, gate_output))\n",
    "        all_outputs_idx = np.unique(all_outputs_idx).astype(int)\n",
    "        next_brain[all_outputs_idx] = 0\n",
    "            \n",
    "\n",
    "        if np.random.rand()>0.0:\n",
    "            \n",
    "            for gate, input_ids, output_ids in zip(self.gates, self.input_ids, self.output_ids):\n",
    "\n",
    "                mg_input_index, marker = 0, 1\n",
    "                # Create an integer from bytes representation (loop is faster than previous implementation)\n",
    "                for mg_input_id in input_ids:\n",
    "                    if self.brain[mg_input_id]:\n",
    "                        mg_input_index += marker\n",
    "                    marker *= 2\n",
    "                \n",
    "                # Determine the corresponding output values for this Markov Gate\n",
    "                markov_gate_subarray = gate[mg_input_index,:]  # selects a Markov Gate subarray\n",
    "\n",
    "                mg_output_index = np.random.choice(len(markov_gate_subarray),p = markov_gate_subarray)\n",
    "                # Converts the index into a string of '1's and '0's (binary representation)\n",
    "                mg_output_values = np.binary_repr(mg_output_index, width=len(output_ids))  # bin() is much faster than np.binaryrepr()\n",
    "\n",
    "                # Loops through 'mg_output_values' and alter 'self.states'\n",
    "                for i, mg_output_value in enumerate(mg_output_values[:]):\n",
    "                    if mg_output_value == '1':\n",
    "                        next_brain[output_ids[len(output_ids)-1 -i]] = 1   #.astype(np.int32)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            next_brain[6:] = np.random.randint(2,size=3)\n",
    "\n",
    "        # Replace original input values\n",
    "        self.brain = np.copy(next_brain)\n",
    "\n",
    "\n",
    "    # reinit when the genome has no changes, used in fitness evaluation\n",
    "    def simple_reinit(self):\n",
    "        \n",
    "        #self.brain[:6] = 0\n",
    "        #self.brain[10:]=0 # keep hidden nodes' state\n",
    "        self.brain = np.zeros(self.brain_size)\n",
    "        self.score = np.float32(0)\n",
    " \n",
    "        self.end = False # reach the end of maze\n",
    "        self.time_step = 0 # +1 for every move\n",
    "        self.thinking_times = 0 # +1 for every step\n",
    "        #self.life = np.maximum(300, 10*self.maze.length)\n",
    "        self.life = Agent.LIFE\n",
    "        self.pass_maze = 0\n",
    "        \n",
    "        #self.position = np.array([np.random.choice(np.arange(1,self.maze.width-1)), 0])\n",
    "        self.position = np.array([self.maze.door_position[-1], 0]) # in front of the last door\n",
    "        self.trajectory = np.ones((self.life, 2))*-1\n",
    "        self.trajectory[self.time_step,:] = self.position\n",
    "        \n",
    "        self.door_direction()\n",
    "        self.perception()\n",
    "\n",
    "          \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    def init_locate(self):\n",
    "        # if the agent reaches the end of maze, pull it back to the origin\n",
    "        \n",
    "        #self.position = np.array([np.random.choice(np.arange(1,self.maze.width-1)), 0])\n",
    "        self.position = np.array([self.maze.door_position[-1], 0]) # in front of the last door\n",
    "        self.end = False\n",
    "    \n",
    "        self.brain[:Agent.num_inputs] = 0 # reset brain\n",
    "        self.brain[Agent.num_inputs+Agent.num_memory:]=0 # keep hidden nodes' state\n",
    "        \n",
    "        self.door_direction()\n",
    "        self.perception()\n",
    "    \n",
    "\n",
    "        \n",
    "    def door_direction(self):\n",
    "        # let the agent know the first door's position\n",
    "        pass\n",
    "        \"\"\"\n",
    "        next_wall = self.maze.wall_position[0] # the first wall\n",
    "        left = self.maze.maze[1:self.position[0], next_wall]\n",
    "        right = self.maze.maze[self.position[0]:self.maze.width-1, next_wall]\n",
    "        \n",
    "        for land in left:\n",
    "            if land != Maze.WALL: \n",
    "                self.brain[3] = 0\n",
    "                break\n",
    "        for land in right:\n",
    "            if land != Maze.WALL: \n",
    "                self.brain[3] = 1\n",
    "                break\n",
    "        \"\"\"\n",
    "                \n",
    "    def perception(self):\n",
    "        x,y = self.position\n",
    "        #print(\"x=%d, y=%d\", (x,y))\n",
    "        # reset agent's input before set new values\n",
    "        #self.brain[0:3] = 0\n",
    "        #self.brain[4:6] =0\n",
    "        self.brain[:Agent.num_inputs]=0\n",
    "        \n",
    "        if self.maze.maze[x,y+1] == Maze.WALL:\n",
    "            self.brain[0]=1\n",
    "        else: self.brain[0]=0\n",
    "        \n",
    "        if self.maze.maze[x-1,y+1] == Maze.WALL:\n",
    "            self.brain[1]=1\n",
    "        else: self.brain[1]=0\n",
    "        \n",
    "        if self.maze.maze[x+1,y+1] == Maze.WALL:\n",
    "            self.brain[2] = 1\n",
    "        else: self.brain[2]=0\n",
    "        \n",
    "        if self.maze.maze[x-1,y] == Maze.WALL:\n",
    "            self.brain[4]=1\n",
    "        else: self.brain[4]=0\n",
    "        \n",
    "        if self.maze.maze[x+1,y] == Maze.WALL:\n",
    "            self.brain[5]=1\n",
    "        else: self.brain[5]=0\n",
    "        \n",
    "        if y in self.maze.wall_position:\n",
    "            self.brain[3] = self.maze.maze[x, y]\n",
    "        \n",
    "    def random_walk(self, x, y):\n",
    "        # implements exploration\n",
    "        feasible = []\n",
    "\n",
    "        if self.maze.maze[x-1, y] != Maze.WALL:\n",
    "            feasible.append([x-1, y])\n",
    "        if self.maze.maze[x+1, y] != Maze.WALL:\n",
    "            feasible.append([x+1, y])\n",
    "        if self.maze.maze[x, y+1] != Maze.WALL:\n",
    "            feasible.append([x, y+1])\n",
    "\n",
    "        if len(feasible)>0:\n",
    "            idx = np.random.randint(len(feasible))\n",
    "            return feasible[idx]\n",
    "        else:\n",
    "            return [x,y]\n",
    "        \n",
    "    \n",
    "            \n",
    "    \n",
    "    def step(self):\n",
    "        x,y = self.position\n",
    "        r = (self.maze.longest_shortest - self.maze.get_distance_escape(x,y))/self.maze.longest_shortest + self.pass_maze\n",
    "        self.score +=  r\n",
    "        #print(\"x=%d, y=%d, escape_distance=%d, score=%f \" % (x,y,agent.maze.get_distance_escape(x,y), agent.score))\n",
    "        #print(\"value=%f \", (agent.maze.longest_shortest - agent.maze.get_distance_escape(x,y))/agent.maze.longest_shortest)\n",
    "        \n",
    "        \n",
    "        fitness = 0\n",
    "        time_step_shot = self.time_step\n",
    "        self.thinking_times = self.thinking_times + 1\n",
    "  \n",
    "        \n",
    "        if self.thinking_times>self.life-1:# or self.thinking_times >= 3000: \n",
    "            self.end = True\n",
    "            fitness = self.get_fitness()\n",
    "            self.fitness = fitness\n",
    "     \n",
    "        #if np.random.rand()>0.5:\n",
    "\n",
    "        elif self.brain[Agent.num_inputs+Agent.num_memory] == 1 and self.brain[Agent.num_inputs+Agent.num_memory+1] == 0:\n",
    "            if self.maze.maze[x+1,y]==Maze.WALL:\n",
    "                r-= 1\n",
    "            #    self.brain[Agent.num_inputs+Agent.num_memory] = 0\n",
    "            #    self.brain[Agent.num_inputs+Agent.num_memory+1] = 1\n",
    "            #else:\n",
    "\n",
    "            if  self.maze.maze[x+1,y] != Maze.WALL:\n",
    "                self.position = x+1, y\n",
    "                self.time_step = self.time_step+1\n",
    "\n",
    "        elif self.brain[Agent.num_inputs+Agent.num_memory] == 0 and self.brain[Agent.num_inputs+Agent.num_memory+1] == 1:\n",
    "            if self.maze.maze[x-1,y] == Maze.WALL:\n",
    "                r-= 1\n",
    "            #    self.brain[Agent.num_inputs+Agent.num_memory] = 1\n",
    "            #    self.brain[Agent.num_inputs+Agent.num_memory+1] = 0\n",
    "            #else:\n",
    "\n",
    "            if  self.maze.maze[x-1,y] != Maze.WALL:\n",
    "                self.position = x-1, y\n",
    "                self.time_step = self.time_step+1\n",
    "\n",
    "\n",
    "        elif self.brain[Agent.num_inputs+Agent.num_memory] == 1 and self.brain[Agent.num_inputs+Agent.num_memory+1] == 1 \\\n",
    "        or self.brain[Agent.num_inputs+Agent.num_memory] == 0 and self.brain[Agent.num_inputs+Agent.num_memory+1] == 0:\n",
    "        \n",
    "\n",
    "            if self.maze.maze[x,y+1] != Maze.WALL:\n",
    "                #r+=20\n",
    "                self.position = x,y+1\n",
    "                self.time_step = self.time_step+1\n",
    "            else:\n",
    "                r-= 1\n",
    "\n",
    "            \"\"\"\n",
    "            elif y in self.maze.wall_position: # in a door\n",
    "                self.position = x,y+1\n",
    "                self.time_step = self.time_step+1\n",
    "            elif y+1 in self.maze.wall_position and self.maze.maze[x,y+1]!=2: # before a door\n",
    "                #print('before a door >;<')\n",
    "                self.position = x,y+1\n",
    "                self.time_step = self.time_step+1\n",
    "            \"\"\"\n",
    "            x,y = self.position\n",
    "            if y == self.maze.length-1: # reach the end of the maze\n",
    "                self.pass_maze = self.pass_maze + 1\n",
    "                self.init_locate()\n",
    "\n",
    "        #elif self.brain[Agent.num_inputs+Agent.num_memory] == 0 and self.brain[Agent.num_inputs+Agent.num_memory+1] == 0:\n",
    "        #    if self.maze.maze[x,y+1] != Maze.WALL:\n",
    "        #        self.position = x,y+1\n",
    "        #        self.time_step = self.time_step+1\n",
    "        #    else:\n",
    "        #        r-= 15\n",
    "\n",
    "            \"\"\"elif y in self.maze.wall_position: # in a door\n",
    "                self.position = x,y+1\n",
    "                self.time_step = self.time_step+1\n",
    "            elif y+1 in self.maze.wall_position and self.maze.maze[x,y+1]!=2: # before a door\n",
    "                #print('before a door >;<')\n",
    "                self.position = x,y+1\n",
    "                self.time_step = self.time_step+1\n",
    "            \"\"\"\n",
    "\n",
    "          #  x,y = self.position\n",
    "          #  if y == self.maze.length-1: # reach the end of the maze\n",
    "          #      self.pass_maze = self.pass_maze + 1\n",
    "          #      self.init_locate()\n",
    "                \n",
    "            #self.position = x,y\n",
    "            #self.time_step = self.time_step+1\n",
    "            '''else:\n",
    "                # shouldn't have this\n",
    "                self.brain[10] = 1\n",
    "                self.brain[11] = 0\n",
    "            '''    \n",
    "        '''elif self.brain[10] == 0 and self.brain[11] == 0:\n",
    "            self.brain[10] = 0\n",
    "            self.brain[11] = 1\n",
    "        ''' \n",
    "        \"\"\"else:\n",
    "            xx, yy = self.random_walk(x,y)\n",
    "            self.position = xx, yy\n",
    "            self.time_step = self.time_step+1\n",
    "            \n",
    "            x,y = self.position\n",
    "            if y == self.maze.length-1: # reach the end of the maze\n",
    "                self.pass_maze = self.pass_maze + 1\n",
    "                self.init_locate()\n",
    "\"\"\"\n",
    "            \n",
    "        # if the brain's order is legal, keep it\n",
    "        # illegal order is omitted\n",
    "        if self.time_step > time_step_shot:    \n",
    "            self.trajectory[self.time_step,:] = self.position\n",
    "        \n",
    "        return fitness, r\n",
    "    \n",
    "    def get_fitness(self):\n",
    "        \n",
    "        return self.score/self.maze.best_score \n",
    "    \n",
    "    def best_brain_update(self):\n",
    "    \n",
    "        next_brain = np.copy(self.brain)\n",
    "        \n",
    "        all_outputs_idx = np.array([])\n",
    "        for gate_output in self.best_output_ids:\n",
    "            all_outputs_idx = np.concatenate((all_outputs_idx, gate_output))\n",
    "        all_outputs_idx = np.unique(all_outputs_idx).astype(int)\n",
    "        next_brain[all_outputs_idx] = 0\n",
    "        \n",
    "        for gate, input_ids, output_ids in zip(self.best_gates, self.best_input_ids, self.best_output_ids):\n",
    "\n",
    "            mg_input_index, marker = 0, 1\n",
    "            # Create an integer from bytes representation (loop is faster than previous implementation)\n",
    " \n",
    "            for mg_input_id in input_ids:\n",
    "                if self.brain[mg_input_id]:\n",
    "                    mg_input_index += marker\n",
    "                marker *= 2\n",
    "           \n",
    "            # Determine the corresponding output values for this Markov Gate\n",
    "            markov_gate_subarray = gate[mg_input_index,:]  # selects a Markov Gate subarray\n",
    "            \n",
    "            #print(self.brain[input_ids], mg_input_index, markov_gate_subarray)\n",
    "\n",
    "            mg_output_index = np.random.choice(len(markov_gate_subarray),p = markov_gate_subarray)\n",
    "            # Converts the index into a string of '1's and '0's (binary representation)\n",
    "            mg_output_values = np.binary_repr(mg_output_index, width=len(output_ids)) #bin(mg_output_index)  # bin() is much faster than np.binaryrepr()\n",
    "            #print(mg_output_values)\n",
    "            # Loops through 'mg_output_values' and alter 'self.states'\n",
    "           \n",
    "            for i, mg_output_value in enumerate(mg_output_values[:]):\n",
    "                if mg_output_value == '1':\n",
    "                    next_brain[output_ids[len(output_ids)-1 -i]] = 1   #.astype(np.int32)\n",
    "        self.brain = np.copy(next_brain)\n",
    "    \n",
    "\n",
    "    def num2action(self, num):\n",
    "        numbers = {\n",
    "            0 : '011',\n",
    "            1 : '100',\n",
    "            2 : '110',\n",
    "            3 : '111'\n",
    "        }\n",
    "        return numbers.get(num, None)\n",
    "    \n",
    "    def brain_update_condense(self):\n",
    "        # differ with gate\n",
    "        next_brain = np.copy(self.brain)\n",
    "        #next_brain[6:] = 0\n",
    "        \n",
    "        all_outputs_idx = np.array([])\n",
    "        for gate_output in self.output_ids:\n",
    "            all_outputs_idx = np.concatenate((all_outputs_idx, gate_output))\n",
    "        all_outputs_idx = np.unique(all_outputs_idx).astype(int)\n",
    "        next_brain[all_outputs_idx] = 0\n",
    "            \n",
    "\n",
    "\n",
    "        for gate, input_ids, output_ids in zip(self.gates, self.input_ids, self.output_ids):\n",
    "\n",
    "            mg_input_index, marker = 0, 1\n",
    "            # Create an integer from bytes representation (loop is faster than previous implementation)\n",
    "            for mg_input_id in input_ids:\n",
    "                if self.brain[mg_input_id]:\n",
    "                    mg_input_index += marker\n",
    "                marker *= 2\n",
    "\n",
    "            # Determine the corresponding output values for this Markov Gate\n",
    "            markov_gate_subarray = gate[mg_input_index,:]  # selects a Markov Gate subarray\n",
    "\n",
    "            mg_output_index = np.random.choice(len(markov_gate_subarray),p = markov_gate_subarray)\n",
    "            \n",
    "            mg_output_values = self.num2action(mg_output_index)\n",
    "\n",
    "            # Loops through 'mg_output_values' and alter 'self.states'\n",
    "            for i, mg_output_value in enumerate(mg_output_values[:]):\n",
    "                if mg_output_value == '1':\n",
    "                    next_brain[output_ids[len(output_ids)-1 -i]] = 1   #.astype(np.int32)\n",
    "\n",
    "\n",
    "        # Replace original input values\n",
    "        self.brain = np.copy(next_brain)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def test():        \n",
    "    maze = Maze(10, 50)\n",
    "    maze.print_maze()\n",
    "    print(maze.best_score)\n",
    "\n",
    "    agent = Agent(maze)\n",
    "    agent.input_ids = agent.best_input_ids\n",
    "    agent.output_ids = agent.best_output_ids\n",
    "    \n",
    "    for i in range(100):\n",
    "        for input_ids, output_ids in zip(agent.input_ids, agent.output_ids):\n",
    "            gate = np.random.rand(2**len(input_ids), 2**2)\n",
    "            gate = gate.astype(np.float64) / np.sum(gate, axis=1, dtype=np.float64)[:, None]\n",
    "            #print(gate)\n",
    "            agent.gates.append(gate)\n",
    "            \n",
    "        #agent.gates = agent.best_gates\n",
    "        agent.simple_reinit()\n",
    "        while (agent.end == False):\n",
    "            agent.perception()\n",
    "            #print(\"step :\", agent.position, agent.brain)\n",
    "            agent.brain_update_condense()\n",
    "            fitness,r = agent.step()\n",
    "\n",
    "\n",
    "        print(fitness)\n",
    "        #print(agent.trajectory)\n",
    "        #print(agent.gene)\n",
    "\n",
    "    \n",
    "np.random.seed(1)       \n",
    "#test()\n",
    "        \n",
    "                \n",
    "    \n",
    "#np.random.seed(9)\n",
    "#import cProfile\n",
    "#cProfile.run('test()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.set_printoptions(precision=6)\n",
    "\n",
    "def Draw(fitness):\n",
    "    plt.plot(np.arange(len(fitness)), fitness, color='green', label='fitness trend',linestyle = '-')\n",
    "    plt.xlabel(\"Episodes\")\n",
    "    plt.ylabel(\"Fitness\")\n",
    "    plt.legend() # 显示图例\n",
    "    plt.show()\n",
    "\n",
    "def num2action(num):\n",
    "    # set the output nodes according to the action\n",
    "    # used when have an action and want to set the output nodes\n",
    "        numbers = {\n",
    "            0 : '011',\n",
    "            1 : '100',\n",
    "            2 : '110',\n",
    "            3 : '111'\n",
    "        }\n",
    "        return numbers.get(num, None)\n",
    "    \n",
    "def action2num(action):\n",
    "    # get the action according to the output nodes\n",
    "    # used when have the action and want to get the action index and update q_table\n",
    "    numbers = {\n",
    "            '011':0,\n",
    "            '100':1,\n",
    "            '110':2,\n",
    "            '111':3\n",
    "        }\n",
    "    return numbers.get(action, None)\n",
    "    \n",
    "    \n",
    "def observation2index(observation): \n",
    "    # observation: array\n",
    "    # get the state index in the q-table\n",
    "    input_val, marker = 0, 1\n",
    "        \n",
    "    for val in observation: # 03456\n",
    "        if val == 1:\n",
    "            input_val += marker\n",
    "        marker *= 2\n",
    "    return int(input_val)\n",
    "    \n",
    "    \n",
    "class QLearningTable:\n",
    "    def __init__(self, N_input_ids, N_output_ids, learning_rate=0.01, reward_decay=0.98, e_greedy=0.5):\n",
    "        self.actions = actions  # a list\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.epsilon = e_greedy\n",
    "        self.q_table = np.zeros((2**N_input_ids, 2**2))\n",
    "        #pd.DataFrame(columns=self.actions, dtype=np.float64)\n",
    "    \n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        # action selection\n",
    "        if np.random.uniform() < self.epsilon: # choose best action\n",
    "            \n",
    "            input_val = observation2index(observation)\n",
    "            \n",
    "            state_action = self.q_table[input_val, :]\n",
    "            # some actions may have the same value, randomly choose on in these actions\n",
    "            max_index = np.argwhere(state_action == np.max(state_action)).flatten().tolist()\n",
    "            output_val = np.random.choice(max_index)\n",
    "            #print(observation, input_val, state_action, max_index, output_val, num2action(output_val))\n",
    "        else:\n",
    "            # choose random action\n",
    "            output_val = np.random.choice(2**2)\n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "        return num2action(output_val)\n",
    "\n",
    "    def learn(self, s, a, r, s_):\n",
    "        input_val = observation2index(s)\n",
    "        action = action2num(str(a))\n",
    "        q_predict = self.q_table[input_val, action]\n",
    "        \n",
    "        next_input_val = observation2index(s_)\n",
    "        #if s_ != 'terminal':\n",
    "        q_target = r + self.gamma * self.q_table[next_input_val, :].max()  # next state is not terminal\n",
    "        #else:\n",
    "        #    q_target = r  # next state is terminal\n",
    "        self.q_table[input_val, action] += self.lr * (q_target - q_predict)  # update\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "actions = ['011','100','110','111']\n",
    "def update():\n",
    "    maze = Maze(10,50)\n",
    "    maze.print_maze()\n",
    "    agent = Agent(maze)\n",
    "    observation_index = agent.best_input_ids[0]\n",
    "    action_index = agent.best_output_ids[0]\n",
    "    \n",
    "    RL = QLearningTable(len(observation_index), len(action_index))\n",
    "    \n",
    "    experience_buffer = []\n",
    "    \n",
    "    Num_episode = 3000\n",
    "    fitness = np.zeros(Num_episode)\n",
    "    average_reward = np.zeros(Num_episode)\n",
    "    \n",
    "    for episode in range(Num_episode):\n",
    "        maze = Maze(10,50)\n",
    "        agent.maze = maze\n",
    "        agent.simple_reinit()\n",
    "        rewards = []\n",
    "        while agent.end==False:\n",
    "            agent.perception()\n",
    "            observation = agent.brain[observation_index]\n",
    "            if (episode == Num_episode-1):\n",
    "                print(\"step :\", agent.position, agent.brain)\n",
    "            #agent.brain_update_condense()\n",
    "            action = RL.choose_action(observation)\n",
    "\n",
    "            agent.brain[action_index] = 0\n",
    "            for ind, i in enumerate(action):\n",
    "                if i == '1':\n",
    "                    agent.brain[8-ind] = 1\n",
    "                    \n",
    "\n",
    "            fitness[episode], reward = agent.step()\n",
    "            rewards.append(reward)\n",
    "            observation_ = agent.brain[observation_index]\n",
    "   \n",
    "                \n",
    "\n",
    "       \n",
    "\n",
    "            # RL learn from this transition\n",
    "            RL.learn(observation, action, reward, observation_)\n",
    "\n",
    "            # swap observation\n",
    "            observation = observation_\n",
    "        average_reward[episode] = np.mean(rewards)\n",
    "\n",
    "    print(np.stack(rewards))\n",
    "    Draw(fitness)\n",
    "    Draw(average_reward)\n",
    "    print(RL.q_table)\n",
    "    # end of game\n",
    "    print('game over')\n",
    "\n",
    "np.random.seed(0)\n",
    "update()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
