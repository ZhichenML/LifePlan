### AutoRL

1. [*Network In Network* by Min Lin & Shuicheng Yan et al. in ICLR2014](https://openreview.net/forum?id=ylE6yojDR5yqX) <!--"includes micro multi-layer
   perceptrons into the filters of convolutional layers to extract more complicated features."[8]-->

   > "includes micro multi-layer perceptrons into the filters of convolutional layers to extract more complicated features." [8]

2. [Training Very Deep Networks, by Rupesh Kumar Srivastava et al. in NIPS2015](https://papers.nips.cc/paper/5850-training-very-deep-networks.pdf): *Highway network*

3. [Going Deeper with Convolutions by Christian Szegedy et al. in CVPR2015](https://arxiv.org/abs/1409.4842):<!--Wider GoogLeNet with an inception module which concatenates feature-maps produced by filters of different sizes--> 

4. [***Deep Residual Learning for Image Recognition***, by Kaiming He et al. in CVPR2016 ](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf): <u>*ResNet*, H(x) = F(x) + x, the rest of the network is refered to approximate F(x) = H(x) - x, by adding input x to network blocks.</u>

5. [Deep Networks with Stochastic Depth by Gao Huang et al. in ECCV2016](https://arxiv.org/abs/1603.09382): *Stochastic Depth Network*

6. [Identity Mappings in Deep Residual Networks, by Kaiming He et al. in ECCV2016](https://arxiv.org/abs/1603.05027): *Pre-activation ResNet*

7. [Rethinking the Inception Architecture for Computer Vision by Christian Szegedy et al. in CVPR2016](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf):<!--Wider GoogLeNet with an inception module which concatenates feature-maps produced by filters of different sizes-->

8. [Densely Connected Convolutional Networks by Gao Huang et al. in CVPR2017](http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Densely_Connected_Convolutional_CVPR_2017_paper.pdf): *DenseNet*

9. [***Exploring Randomly Wired Neural Networks for Image Recognition***, by Saining Xie et al. in Arxiv2019](https://arxiv.org/pdf/1904.01569.pdf): <u>*RandomWired Network*, Thestrategy to generate the network, or network generator stated in the paper, introduce prior bias to the generated network and limit the network search space to a subspce. To circumvent the prior bias, this paper tries to explot random graphs as network generator and transform the graph into neural networks. The node operation is predifined and universal. It is similar to our idea of letting the network emerge itself, rather than pre-define any network types. </u> 

10. 

